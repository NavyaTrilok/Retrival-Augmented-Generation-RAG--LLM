{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KxRx_RQaaimR",
    "outputId": "3d000839-bb04-4322-9abb-c9c72a7d058d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, faiss-cpu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed faiss-cpu-1.11.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers sentence-transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLGsPHL7bT1n"
   },
   "source": [
    "if using gpu use faiss-gpu\n",
    "\n",
    "in change runtime type we can change gpu, tpu, we can pay and use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IzzBTsR2bM7s"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import textwrap\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MIm4vjzTb1Do"
   },
   "outputs": [],
   "source": [
    "def load_and_chunk(file_path, chunk_size=300, overlap = 100):\n",
    "  with open(file_path,'r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "  chunks = []\n",
    "  start = 0\n",
    "  while start < len(text):\n",
    "    chunks.append(text[start:start + chunk_size])\n",
    "    start += chunk_size - overlap\n",
    "  return chunks\n",
    "\n",
    "chunks = load_and_chunk('pizza.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xxFRMLdIeRJr",
    "outputId": "e1c68af2-1899-4351-9a3a-938e2164669d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "M_-YDplBdA9L",
    "outputId": "48087ea7-09a4-4712-c3e5-4a5fe8f1eff9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'iginating from the sun-kissed lands of Italy, pizza has evolved into an art form that unites people from diverse backgrounds in a shared love for its mouthwatering combinations. Its history stretches back centuries, with roots tracing back to ancient civilizations like the Greeks, Romans, and Egypti'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wPhrjVsJdQII"
   },
   "outputs": [],
   "source": [
    "#using bert model\n",
    "\n",
    "embedder = SentenceTransformer(\"sentence-transformers/bert-base-nli-mean-tokens\")\n",
    "\n",
    "#pretrained model\n",
    "#uisng bert model and simply encode the chunks, it takes little bit time, we are doing word embedding, that chunks of data\n",
    "#is converted into embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b5f1a83b762e479abdda291fdecebbe9",
      "15c68aa7250f438baeb78ffda519b25f",
      "52e6f6b73df14cb99026ea24c5eb84b8",
      "6f1129a305814c0e817d0a6bb0143542",
      "d4e8fa9731184018ae681c6773e11455",
      "1ed6ac8301d643488554ebdea65f7b87",
      "a65063f8e7c34d408e508dc309592610",
      "baba6724ba9b4982bcebb75bfab93b05",
      "c9fa4a7c211a4fd2990536367a4623ec",
      "276835312ed3464883482f449fae8b66",
      "5b97ac7135dc4bb3805ea34220de8194"
     ]
    },
    "id": "DCsRCd8ndjHT",
    "outputId": "49762095-f871-41f6-cef8-e49e715a7a5c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f1a83b762e479abdda291fdecebbe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunk_embeddings = embedder.encode(chunks, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4v2Q1D4Pd9P9",
    "outputId": "b0ad105d-1a66-4505-a5ba-4922c51260a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 768)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_embeddings.shape #28 chunks 768 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBgSUu1heCpj",
    "outputId": "ff5c31cc-77d8-4953-a97b-99ea3e6b42b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exLgP9mceFna",
    "outputId": "c155d13f-c667-4fa4-c18f-715707e1e656"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.20914185e-01,  2.75622010e-01,  5.99907815e-01, -8.37260067e-01,\n",
       "        1.16918132e-01, -7.86106884e-01, -5.81611335e-01,  9.53733444e-01,\n",
       "        6.46697342e-01, -6.39264822e-01,  3.26622039e-01,  7.08555162e-01,\n",
       "        8.10500801e-01,  5.57982028e-01, -4.57581520e-01, -8.88048932e-02,\n",
       "        5.30135691e-01, -1.81167334e-01, -4.05893922e-01, -1.77109703e-01,\n",
       "        1.83328222e-02, -4.55846488e-01, -2.47630998e-01,  6.97148979e-01,\n",
       "        2.23228812e-01,  5.14841080e-01, -2.49408841e-01, -6.41279593e-02,\n",
       "       -1.24830559e-01,  1.44995809e-01, -5.43251097e-01,  7.62264192e-01,\n",
       "       -6.98695779e-01, -1.29399979e+00, -5.88165283e-01,  5.91978490e-01,\n",
       "        7.26240158e-01, -4.13944781e-01, -2.37656265e-01,  6.26204550e-01,\n",
       "        2.98519462e-01, -7.79117882e-01,  9.83993113e-01,  2.97231581e-02,\n",
       "       -1.08141232e+00, -2.97381170e-02, -6.21856153e-01,  1.11568105e+00,\n",
       "        4.35300231e-01, -4.71147090e-01,  1.86175358e+00, -6.37483418e-01,\n",
       "       -7.33975410e-01, -4.94866073e-01,  1.30885273e-01,  8.82354319e-01,\n",
       "       -5.64094841e-01, -4.43458647e-01,  7.45200336e-01, -8.92976165e-01,\n",
       "       -4.31243002e-01,  9.14904177e-01, -1.64074183e-01, -4.29106474e-01,\n",
       "       -5.92444897e-01,  4.34655428e-01,  4.33115035e-01,  3.53248090e-01,\n",
       "       -7.10704386e-01, -2.92738527e-01, -2.51151957e-02, -9.25665796e-01,\n",
       "       -5.41239023e-01, -2.97793895e-01, -3.72939736e-01, -6.77468657e-01,\n",
       "       -5.98298907e-01,  5.77413321e-01,  3.75538856e-01,  3.36174458e-01,\n",
       "       -2.76500851e-01, -4.51201290e-01,  2.80521244e-01,  3.59088302e-01,\n",
       "        1.52773783e-01,  4.75499809e-01,  6.22547984e-01, -3.28801394e-01,\n",
       "       -3.97581249e-01,  1.48586491e-02,  2.03306511e-01, -6.08204246e-01,\n",
       "        1.20701730e+00, -1.02364445e+00, -3.71451795e-01, -6.87883258e-01,\n",
       "        1.27039641e-01,  1.18661940e-01, -7.83231258e-01,  5.39234877e-01,\n",
       "       -1.29152906e+00,  1.20009920e-02, -4.06134903e-01,  4.80308622e-01,\n",
       "        5.97265288e-02,  5.34557760e-01, -4.34976518e-02, -2.92295039e-01,\n",
       "        4.30492848e-01,  3.88673484e-01,  6.72512650e-01, -3.08355987e-01,\n",
       "       -3.89255017e-01,  2.29817957e-01, -4.69395906e-01, -3.71187121e-01,\n",
       "       -7.33910024e-01,  4.73914772e-01,  6.61105588e-02, -4.84690428e-01,\n",
       "        2.54294332e-02, -1.05548251e+00, -1.78172126e-01,  1.26705587e-01,\n",
       "        3.73487562e-01, -2.10112244e-01,  3.20273608e-01,  5.74342132e-01,\n",
       "       -4.90780145e-01, -2.19123274e-01,  1.94978461e-01,  3.96026939e-01,\n",
       "       -3.83833617e-01, -1.58962429e-01,  1.53024182e-01,  9.85470414e-01,\n",
       "       -3.37782339e-03, -8.38751853e-01, -3.20081562e-01, -4.95799258e-02,\n",
       "       -5.61385512e-01, -7.77760446e-01,  2.72548825e-01, -1.15620911e+00,\n",
       "       -2.49775723e-01, -2.63564259e-01,  8.92143250e-01, -2.35622093e-01,\n",
       "        5.43349385e-01, -1.07606447e+00,  8.55402708e-01, -4.72032130e-01,\n",
       "       -1.39645576e+00,  1.69741195e-02,  8.23278800e-02,  1.08153313e-01,\n",
       "       -6.83683038e-01,  3.29754442e-01, -8.62488672e-02,  5.31091057e-02,\n",
       "       -2.76362002e-01, -9.46330130e-02, -1.50740579e-01,  5.96642196e-01,\n",
       "       -9.06509608e-02, -5.39707422e-01,  1.27088141e+00,  7.60195553e-02,\n",
       "       -5.30619025e-01,  6.30855739e-01, -2.18433708e-01,  9.13900495e-01,\n",
       "        1.40479064e+00,  6.21619403e-01,  7.06841946e-01,  1.91752389e-01,\n",
       "        3.85491639e-01,  1.32107541e-01, -1.81128725e-01, -1.09848566e-01,\n",
       "       -6.91607371e-02, -5.06814003e-01, -3.79269481e-01, -1.25452578e-01,\n",
       "        4.69235301e-01, -1.04083860e+00,  4.66235101e-01, -2.24495724e-01,\n",
       "        2.25026667e-01,  4.33002442e-01,  1.96174175e-01, -2.34040946e-01,\n",
       "       -3.49961549e-01, -8.39568019e-01, -2.98348814e-01,  6.77280247e-01,\n",
       "       -8.03926289e-01,  9.55618620e-01,  1.80867434e-01,  1.02045760e-01,\n",
       "       -4.74521786e-01,  3.18794042e-01,  9.79347169e-01, -1.08538479e-01,\n",
       "       -1.67800095e-02, -1.33490607e-01,  2.39374846e-01,  4.43465933e-02,\n",
       "       -5.91891289e-01, -6.54275775e-01, -2.35963523e-01,  4.64630514e-01,\n",
       "        4.47951376e-01, -5.88886917e-01, -3.41349602e-01,  4.76540685e-01,\n",
       "        3.93553048e-01,  7.38563359e-01,  5.48396349e-01, -9.02692437e-01,\n",
       "        9.24177542e-02,  5.34374177e-01, -3.74440670e-01,  2.77269334e-01,\n",
       "       -2.20097497e-01,  9.01557386e-01, -2.67581880e-01, -8.65649223e-01,\n",
       "       -5.48537485e-02,  5.73004365e-01,  1.31466970e-01, -3.84769708e-01,\n",
       "       -1.86011232e-02, -2.20921896e-02,  9.91636291e-02, -1.40954703e-01,\n",
       "        9.85261500e-02,  4.11287367e-01,  9.99604702e-01, -5.09021401e-01,\n",
       "        7.73360670e-01,  5.51060498e-01, -6.01298571e-01, -3.64400148e-02,\n",
       "       -3.54050994e-01, -2.44900420e-01,  8.11178684e-01,  4.57146198e-01,\n",
       "       -3.73593330e-01,  6.53698802e-01, -7.01574326e-01, -1.56426638e-01,\n",
       "        5.33236206e-01, -3.83338742e-02,  6.78586960e-01, -1.13107431e+00,\n",
       "       -2.98171043e-01,  4.25110698e-01, -3.19203623e-02, -4.38684940e-01,\n",
       "        1.67460799e-01, -5.34142435e-01, -1.62923858e-01,  9.35781524e-02,\n",
       "       -2.83211976e-01,  4.25112575e-01, -7.47053266e-01, -1.09602742e-01,\n",
       "        1.34223253e-01,  1.47466004e-01, -5.11789136e-02, -1.90390032e-02,\n",
       "       -5.92036366e-01,  9.10214365e-01,  6.16574027e-02, -3.12571555e-01,\n",
       "       -8.13267827e-01, -2.21542597e-01,  4.37946439e-01,  1.94820330e-01,\n",
       "        8.73446912e-02, -7.75029361e-02, -1.42495048e+00, -3.74666601e-01,\n",
       "       -1.09133565e+00,  5.94826400e-01,  1.16193593e-01, -6.10504329e-01,\n",
       "       -3.38520378e-01,  2.64775187e-01,  9.75815594e-01, -2.61734247e-01,\n",
       "       -4.77692246e-01, -4.25648808e-01,  5.23317099e-01, -2.85583973e-01,\n",
       "        1.25136375e+00, -7.34545350e-01,  4.08001482e-01, -2.23393530e-01,\n",
       "        1.43022701e-01, -1.08489148e-01, -7.61434793e-01,  1.00270700e+00,\n",
       "        2.22708896e-01,  4.87148501e-02,  2.54571140e-01, -1.12812199e-01,\n",
       "       -3.81053418e-01, -6.57344759e-01, -5.68670511e-01,  2.80724257e-01,\n",
       "       -6.93145767e-02,  7.11889923e-01,  3.91301334e-01, -3.26410919e-01,\n",
       "       -4.65297341e-01, -9.91994590e-02,  1.37203529e-01, -8.16299975e-01,\n",
       "        1.86447967e-02,  4.48957115e-01, -7.87968934e-02, -5.80259115e-02,\n",
       "       -1.25521988e-01, -9.45883393e-01, -4.65534717e-01,  2.50704497e-01,\n",
       "       -4.80797410e-01, -7.51753271e-01,  4.17249739e-01,  2.24750713e-02,\n",
       "        2.49271721e-01,  6.52023256e-01, -7.48792410e-01,  6.31331444e-01,\n",
       "       -9.80829835e-01, -2.98098493e-02, -2.64591485e-01, -1.63312823e-01,\n",
       "        1.31603062e+00, -7.89515078e-02,  6.64554238e-01, -2.24772736e-01,\n",
       "        7.26203918e-01, -3.43947530e-01,  2.17128187e-01,  4.22070503e-01,\n",
       "       -4.95432794e-01, -1.65511519e-02,  9.08502042e-02, -9.67970312e-01,\n",
       "        1.16094458e+00, -8.82210076e-01, -1.29699588e-01,  5.26114583e-01,\n",
       "       -4.77302670e-01,  3.13646346e-02, -3.52143437e-01,  6.33022130e-01,\n",
       "       -1.03521310e-02,  5.62061250e-01,  2.33548135e-01,  8.75622630e-02,\n",
       "        2.66278148e-01,  4.17126358e-01,  2.97865063e-01, -1.59966439e-01,\n",
       "        1.67705178e-01, -2.51519173e-01,  5.70812775e-03,  8.18892896e-01,\n",
       "       -5.06011069e-01,  7.61620522e-01, -3.21826458e-01, -1.79425940e-01,\n",
       "       -1.51865602e+00,  4.65328485e-01, -7.28597715e-02,  2.77112853e-02,\n",
       "        1.45336151e-01, -3.21933836e-01,  4.57524538e-01, -7.50682950e-01,\n",
       "       -1.01095349e-01,  8.07565227e-02, -9.20234546e-02, -2.63693631e-02,\n",
       "       -7.42740110e-02, -3.33475798e-01, -6.70746565e-01,  3.05420876e-01,\n",
       "        2.54730225e-01, -2.39394784e-01,  4.92716096e-02, -2.81563759e-01,\n",
       "       -4.74865496e-01, -6.35063291e-01,  5.58455527e-01, -1.54066965e-01,\n",
       "       -2.61801898e-01,  6.01468980e-01,  2.58798510e-01, -8.83052275e-02,\n",
       "       -5.80489397e-01,  1.09876728e+00,  9.09198463e-01, -1.07128255e-01,\n",
       "        9.26014036e-02, -5.34560263e-01,  5.42065561e-01,  5.16048729e-01,\n",
       "        8.93681109e-01,  2.13242814e-01,  5.30423522e-02, -3.48869711e-01,\n",
       "        5.02736747e-01, -3.83712620e-01, -8.35275471e-01,  1.22656357e+00,\n",
       "       -1.10836434e+00,  7.45370746e-01,  6.37619555e-01, -2.70662099e-01,\n",
       "        3.63700867e-01, -1.90238029e-01, -5.47797263e-01,  5.22932887e-01,\n",
       "       -5.90997711e-02,  6.88677654e-02,  2.78099090e-01,  1.17230378e-01,\n",
       "       -2.24959642e-01, -2.78168887e-01,  1.22423267e+00, -3.62698436e-01,\n",
       "        1.02180088e+00, -8.63558948e-01,  7.19118178e-01, -4.23578054e-01,\n",
       "        3.10173005e-01,  6.65110767e-01,  5.03727913e-01,  6.64252520e-01,\n",
       "       -3.90071601e-01, -7.26812541e-01, -3.14167500e-01,  6.99862838e-01,\n",
       "        7.48007059e-01,  1.97830692e-01,  4.51782197e-01, -3.81255448e-01,\n",
       "       -1.30192861e-01,  9.63425875e-01,  2.30590373e-01,  3.18961084e-01,\n",
       "       -8.68694007e-01,  5.74649930e-01, -4.91051674e-01,  2.88966775e-01,\n",
       "       -2.38706037e-01, -4.25363451e-01,  1.31309450e-01,  1.42153978e-01,\n",
       "        2.77403593e-01,  7.53085494e-01, -5.69813728e-01, -7.72109807e-01,\n",
       "        7.17254817e-01, -8.62509251e-01,  5.22633553e-01,  6.90469384e-01,\n",
       "       -2.11249426e-01,  9.89390433e-01,  3.11591506e-01, -1.31503665e+00,\n",
       "       -1.11750484e+00,  8.24805439e-01,  1.24682756e-02,  1.65572977e+00,\n",
       "        1.73349082e-01, -4.44304466e-01, -3.97989094e-01, -5.62959500e-02,\n",
       "       -2.80682445e-01,  4.95747358e-01, -6.65973008e-01,  3.88220996e-01,\n",
       "       -3.26123416e-01,  2.67649703e-02, -4.07659322e-01,  2.81839888e-03,\n",
       "       -6.15417540e-01, -8.35747302e-01, -2.30562806e-01, -1.98504180e-01,\n",
       "       -6.73849940e-01,  1.90355003e-01, -2.46641356e-02,  8.22198927e-01,\n",
       "        5.39151788e-01, -2.72249192e-01,  1.59073263e-01, -4.95795608e-01,\n",
       "        3.82180870e-01, -1.92936912e-01,  9.74087231e-03, -8.93970132e-01,\n",
       "        1.12396881e-01,  1.31548360e-01, -3.79480213e-01,  3.83625805e-01,\n",
       "        8.91822755e-01,  1.33806527e-01, -2.09765345e-01,  3.12081754e-01,\n",
       "        1.81088969e-01,  5.89791059e-01, -1.81119740e-01, -3.89219075e-01,\n",
       "        6.62469387e-01,  3.93798560e-01,  4.99143809e-01,  3.85242969e-01,\n",
       "       -4.45068568e-01,  5.95795453e-01,  8.58124197e-01, -2.15683639e-01,\n",
       "        1.55791551e-01, -8.93416882e-01, -1.55278563e-01, -1.78302884e-01,\n",
       "       -6.68646097e-02,  1.68107882e-01, -5.70911877e-02,  8.78523052e-01,\n",
       "       -9.46488440e-01, -2.80441910e-01,  2.50214666e-01,  1.80608004e-01,\n",
       "        3.02607179e-01,  5.02840996e-01,  3.93171787e-01, -4.70229052e-03,\n",
       "       -7.41389394e-01, -4.81379360e-01,  5.22401445e-02,  4.86879051e-01,\n",
       "       -1.97797775e-01, -2.54078031e-01, -3.13797534e-01, -3.94117266e-01,\n",
       "        3.25680614e-01,  5.75665653e-01, -4.05977257e-02,  7.63154507e-01,\n",
       "       -1.46111870e+00,  5.13822064e-02, -6.23908937e-01,  8.98294225e-02,\n",
       "        4.94824797e-02,  5.48118353e-01, -5.00780761e-01, -5.10616660e-01,\n",
       "        2.35111117e-01, -9.63436589e-02, -4.37721103e-01, -9.31810856e-01,\n",
       "       -9.95401740e-01,  2.51456738e-01,  5.06308019e-01, -1.13274388e-01,\n",
       "        7.37130165e-01,  2.89949149e-01, -6.88062906e-01, -5.31953573e-01,\n",
       "       -6.31195188e-01, -2.30766043e-01, -3.95600200e-01,  1.07111402e-01,\n",
       "       -8.56409445e-02,  1.77279800e-01,  2.15736121e-01,  9.54352558e-01,\n",
       "        7.15296566e-01, -2.49215454e-01,  6.67125165e-01, -3.30790281e-02,\n",
       "       -1.94531575e-01, -7.47542679e-01, -3.59927863e-01, -7.26102054e-01,\n",
       "       -2.52193987e-01, -1.74262926e-01, -1.40192640e+00,  1.30995527e-01,\n",
       "       -1.60014972e-01,  9.92292106e-01,  2.29622737e-01, -3.83264363e-01,\n",
       "        8.03648651e-01, -8.50842416e-01, -6.10143065e-01,  1.44295961e-01,\n",
       "       -5.47225654e-01, -1.36352837e-01,  4.80854250e-02, -5.63302755e-01,\n",
       "       -1.30021080e-01, -2.01476485e-01, -1.62733719e-01, -7.26226091e-01,\n",
       "       -4.15401220e-01, -1.31537691e-01,  2.21378595e-01, -4.29282367e-01,\n",
       "        1.68131471e-01, -4.30150449e-01,  1.05652280e-01, -9.95191038e-01,\n",
       "        8.75623673e-02,  8.51479590e-01, -4.39274460e-01,  2.24567518e-01,\n",
       "        1.55339992e+00, -6.35412693e-01, -6.64657652e-01,  6.12830043e-01,\n",
       "       -7.04315305e-02, -7.09861696e-01,  1.88177049e-01, -2.51871109e-01,\n",
       "        4.61948752e-01,  3.77138913e-01, -1.12221491e+00,  3.07831854e-01,\n",
       "       -4.97874945e-01,  4.70140666e-01, -1.12946101e-01,  6.34447932e-01,\n",
       "       -1.22847426e+00,  7.20117927e-01, -6.35585725e-01, -4.13919270e-01,\n",
       "        1.37219042e-01,  2.19681710e-01, -3.73399258e-01,  5.48307776e-01,\n",
       "        8.25229704e-01,  7.47732818e-01, -2.10134029e-01,  1.19098258e+00,\n",
       "       -6.54883564e-01,  2.64717378e-02, -1.27843904e+00, -3.49888355e-01,\n",
       "       -3.56524885e-01, -4.10596669e-01, -2.80617952e-01,  7.86304891e-01,\n",
       "        5.50945342e-01,  3.78584445e-01,  6.27711594e-01, -5.10968149e-01,\n",
       "        1.07970141e-01, -3.71669322e-01, -6.38482273e-01,  7.48667061e-01,\n",
       "       -3.21325995e-02,  8.07450116e-01,  1.07303262e+00, -9.71513748e-01,\n",
       "       -1.06495313e-01,  5.54650091e-02, -1.48808122e-01, -6.94569945e-01,\n",
       "       -6.02486134e-01,  9.10786271e-01,  2.34213844e-01, -5.89366257e-01,\n",
       "       -8.83978844e-01, -9.36686397e-01,  4.33077306e-01, -3.15956593e-01,\n",
       "       -2.23970652e-01,  5.41552365e-01, -1.34288594e-01, -3.09430748e-01,\n",
       "       -4.31919962e-01,  5.84407091e-01,  2.77909577e-01,  7.77607501e-01,\n",
       "        3.05681199e-01, -7.65454769e-02, -4.00301039e-01, -1.72005683e-01,\n",
       "       -9.95844960e-01,  4.58700478e-01,  6.88780099e-02,  5.13531193e-02,\n",
       "       -5.36605179e-01,  7.46042371e-01,  5.48314095e-01, -1.17088163e+00,\n",
       "        6.38238668e-01, -1.21207125e-01, -5.26795208e-01, -7.26408243e-01,\n",
       "        5.56859016e-01, -3.97129059e-01,  1.07025528e+00,  3.31329584e-01,\n",
       "        1.01742193e-01,  5.45866787e-01, -8.97441467e-04,  3.20539951e-01,\n",
       "        1.92215353e-01,  1.09696440e-01, -5.62645793e-02, -1.10899121e-01,\n",
       "       -4.24462706e-01, -4.50038433e-01, -5.78799546e-01, -5.07205665e-01,\n",
       "        2.97746211e-01, -5.19031286e-02,  1.43863702e+00,  2.78625824e-02,\n",
       "       -8.56847167e-01, -1.02565549e-01,  1.84434447e-02, -4.78073388e-01,\n",
       "        8.68691057e-02,  2.62855381e-01,  3.44319463e-01,  2.34623373e-01,\n",
       "        5.53807653e-02, -3.34516138e-01, -7.44395256e-01, -3.34321082e-01,\n",
       "        1.47583961e-01, -3.85488033e-01, -3.49709898e-01, -6.52035058e-01,\n",
       "        4.71453130e-01, -2.99099177e-01, -3.42282355e-01,  6.20389938e-01,\n",
       "        4.09749150e-01,  2.50928909e-01, -1.32508138e-02, -1.07764924e+00,\n",
       "        2.87474692e-01,  5.87303638e-01, -1.92206111e-02,  1.01436603e+00,\n",
       "       -4.22122717e-01,  3.06906790e-01, -4.88693506e-01, -1.20837474e+00,\n",
       "       -3.03949267e-01, -1.02247858e+00, -8.85169655e-02, -8.41562867e-01,\n",
       "        4.26599920e-01, -3.29500854e-01, -1.52418781e-02, -1.94189861e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tOrU7fEe-f2"
   },
   "outputs": [],
   "source": [
    "These are meaning ful numbers, not bag of words. bag of words only gives us the occurance.\n",
    "If the word is there then 1 else 0. This is not that kind of data. Each and every word has meaning numbers\n",
    "\n",
    "Eg. king - man + woman = queen\n",
    "\n",
    "royal + man - man + woman = queen\n",
    "\n",
    "Vectors are represented in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "4AoyWemmgMul"
   },
   "outputs": [],
   "source": [
    "dimension = chunk_embeddings[0].shape[0]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(chunk_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxPCF2pahDDY"
   },
   "outputs": [],
   "source": [
    "#DisDistilGPT2 (short for Distilled-GPT2) is an English-language model pre-trained with the supervision of\n",
    "#the smallest version of Generative Pre-trained Transformer 2 (GPT-2). Like GPT-2, DistilGPT2 can be used\n",
    "#to generate text. Users of this model card should also consider information about the design, training, and\n",
    "#limitations of GPT-2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nxErePDGhUl8",
    "outputId": "aa621a3e-bf70-4aa3-e96c-f063f1eb1976"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "gen_model_id = 'distilgpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(gen_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(gen_model_id)\n",
    "generator = pipeline('text-generation',model=model,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "kOYgxXlThtwk"
   },
   "outputs": [],
   "source": [
    "def rag_bert_qa(question, top_k=3, max_tokens=150):\n",
    "  q_embeddings = embedder.encode([question])\n",
    "  distances, indices = index.search(np.array(q_embeddings),top_k)\n",
    "  retrived = \"\\n\".join([chunks[i] for i in indices[0]])\n",
    "\n",
    "\n",
    "  prompt = f\"\"\"Answer the question using context below. Context:{retrived} Question: {question} Answer:\"\"\"\n",
    "  response = generator(prompt,max_new_tokens = max_tokens, do_sample=True, temperature=0.7)\n",
    "  answer = response[0]['generated_text'].split(\"Answer:\")[-1].strip()\n",
    "  return textwrap.fill(answer,width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYu6LZmKjz2X"
   },
   "outputs": [],
   "source": [
    "#questions need to be encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzpxXF7ljFNZ",
    "outputId": "d1436318-a0f7-40fc-9af5-873e3a9b66a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question in which country pizza is more popular?\n",
      "Answer: The United States is the world's most popular pizza destination. The United States is the world's\n",
      "most popular pizza destination. The United States is the world's most popular pizza destination. The\n",
      "United States is the world's most popular pizza destination. The United States is the world's most\n",
      "popular pizza destination. In the United States, the pizza industry is the world's most popular\n",
      "pizza destination. The United States is the world's most popular pizza destination. The United\n",
      "States is the world's most popular pizza destination. In the United States, the pizza industry is\n",
      "the world's most popular pizza destination. The United States is the world's most popular pizza\n",
      "destination. The United States is the world's most popular pizza destination. In the United States\n"
     ]
    }
   ],
   "source": [
    "query = \"in which country pizza is more popular?\"\n",
    "print(\"Question\",query)\n",
    "print(\"Answer:\",rag_bert_qa(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6oWx9oKjm9h",
    "outputId": "d60b0e97-32d3-4e66-ecff-0b24647df438"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question what is the shape of pizza?\n",
      "Answer: it is a pizza. The pizza industry has expanded exponentially, with\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the shape of pizza?\"\n",
    "print(\"Question\",query)\n",
    "print(\"Answer:\",rag_bert_qa(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8pFSNtElC5N"
   },
   "outputs": [],
   "source": [
    "# we have only taken small chunks of data to train\n",
    "# every time we run it may give different results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avRXIBfbldMK",
    "outputId": "e4ac9381-8de2-435c-f829-931f59f225f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question In which country pizza is first made?\n",
      "Answer: Italy. The Italian pizza is made from a mixture of fresh and fresh basil, with a mixture of fresh\n",
      "and fresh basil, with a mixture of fresh and fresh basil, with a mixture of fresh and fresh basil,\n",
      "with a mixture of fresh and fresh basil, with a mixture of fresh and fresh basil, with a mixture of\n",
      "fresh and fresh basil, with a mixture of fresh and fresh basil, with a mixture of fresh and fresh\n",
      "basil, with a mixture of fresh and fresh basil, with a mixture of fresh and fresh basil, with a\n",
      "mixture of fresh and fresh basil, with a mixture of fresh and fresh basil, with a mixture of fresh\n",
      "and fresh basil, with a mixture of fresh and fresh basil, with a mixture of fresh and fresh\n"
     ]
    }
   ],
   "source": [
    "query = \"In which country pizza is first made?\"\n",
    "print(\"Question\",query)\n",
    "print(\"Answer:\",rag_bert_qa(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjGDtVKHljxq",
    "outputId": "a71791a7-d715-4620-8500-bf0283753e7c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question what is the taste of the pizza?\n",
      "Answer: it is a pizza that is made from a variety of ingredients. It is a pizza that is made from a variety\n",
      "of ingredients. It is a pizza that is made from a variety of ingredients. It is a pizza that is made\n",
      "from a variety of ingredients. It is a pizza that is made from a variety of ingredients. It is a\n",
      "pizza that is made from a variety of ingredients. It is a pizza that is made from a variety of\n",
      "ingredients. It is a pizza that is made from a variety of ingredients. It is a pizza that is made\n",
      "from a variety of ingredients. It is a pizza that is made from a variety of ingredients. It is a\n",
      "pizza that is made from a variety of ingredients. It is a pizza that is made\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the taste of the pizza?\"\n",
    "print(\"Question\",query)\n",
    "print(\"Answer:\",rag_bert_qa(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DpOjcIbklpq7"
   },
   "outputs": [],
   "source": [
    "# It understandes the context also\n",
    "\n",
    "#Here it is repeadetly generating the same data because it is trained on small data\n",
    "\n",
    "# we make temperature = 0.7 means we are giving free hand to generate the text data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVac3zjbmGkT"
   },
   "outputs": [],
   "source": [
    "It will take lot of time to train, that's why we use gpu\n",
    "\n",
    "pizza.txt is 10 KB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQ7QNSbnuE9X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "15c68aa7250f438baeb78ffda519b25f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ed6ac8301d643488554ebdea65f7b87",
      "placeholder": "​",
      "style": "IPY_MODEL_a65063f8e7c34d408e508dc309592610",
      "value": "Batches: 100%"
     }
    },
    "1ed6ac8301d643488554ebdea65f7b87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "276835312ed3464883482f449fae8b66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52e6f6b73df14cb99026ea24c5eb84b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_baba6724ba9b4982bcebb75bfab93b05",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c9fa4a7c211a4fd2990536367a4623ec",
      "value": 1
     }
    },
    "5b97ac7135dc4bb3805ea34220de8194": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f1129a305814c0e817d0a6bb0143542": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_276835312ed3464883482f449fae8b66",
      "placeholder": "​",
      "style": "IPY_MODEL_5b97ac7135dc4bb3805ea34220de8194",
      "value": " 1/1 [00:11&lt;00:00, 11.82s/it]"
     }
    },
    "a65063f8e7c34d408e508dc309592610": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5f1a83b762e479abdda291fdecebbe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_15c68aa7250f438baeb78ffda519b25f",
       "IPY_MODEL_52e6f6b73df14cb99026ea24c5eb84b8",
       "IPY_MODEL_6f1129a305814c0e817d0a6bb0143542"
      ],
      "layout": "IPY_MODEL_d4e8fa9731184018ae681c6773e11455"
     }
    },
    "baba6724ba9b4982bcebb75bfab93b05": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9fa4a7c211a4fd2990536367a4623ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d4e8fa9731184018ae681c6773e11455": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
